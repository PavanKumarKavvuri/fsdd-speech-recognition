{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed89fd2-ddcc-44f0-8112-82a1a5fdb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root (parent of current folder) to Python path\n",
    "project_root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54a9aad5-b2f2-46f6-a5fc-352f5544eb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "import src.utils as utils\n",
    "\n",
    "utils.set_seed(42)\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "model_config_path = os.path.join(project_root_dir, 'config', 'model_config.yaml')\n",
    "model_config = utils.read_yaml_file(model_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35715089-18cd-4d63-837d-eb606609e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = model_config['dataset']['path']\n",
    "test_data_size = model_config['data_splitting']['test_size']\n",
    "seed = model_config['experiment']['seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d23256-4e4b-4d5b-ba9a-385db849ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_pairs = utils.prepare_data_label_pairs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7130c1-4ced-46fb-9552-6cc71e8c13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data_label_pairs, test_size=test_data_size, random_state=seed)\n",
    "\n",
    "\n",
    "from src.data_preprocessor import AudioFeaturesDataset\n",
    "\n",
    "train_dataset = AudioFeaturesDataset(train_data)\n",
    "test_dataset = AudioFeaturesDataset(test_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e662b2c-c092-4638-838d-4133dc017667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fb07d-40c8-42a6-b962-38457b558eb3",
   "metadata": {},
   "source": [
    "## ADD MARKDOWN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47294760-4ebb-438d-aa20-fc43a8bbe56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = model_config['model']['input_dim']\n",
    "hidden_dim = model_config['model']['hidden_dim']\n",
    "num_layers = model_config['model']['num_layers']\n",
    "output_dim = model_config['model']['output_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c4fd204-8f00-44dd-a22f-dd66c57065ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a3db51b-4d6c-40e8-8911-3ba70a468498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spectgramer)",
   "language": "python",
   "name": "innatera-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
