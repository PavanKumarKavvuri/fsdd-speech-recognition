{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074e24f9-a286-43cd-965b-1c41044ee99b",
   "metadata": {},
   "source": [
    "# LSTM for Spoken Digit Classification\n",
    "\n",
    "This notebook builds and trains a recurrent neural network (LSTM) to classify spoken digits (0–9) from audio recordings.\n",
    "\n",
    "- Dataset: [Free Spoken Digit Dataset (FSDD)](https://github.com/Jakobovski/free-spoken-digit-dataset)\n",
    "- Framework: PyTorch\n",
    "- Architecture: RNN with LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac121864-dea8-4206-b0d1-1acbdc0002dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root (parent of current folder) to Python path\n",
    "project_root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907bf1a-f498-4c4b-941a-1ec9859a6dbc",
   "metadata": {},
   "source": [
    "## Load Model Configuration from YAML\n",
    "\n",
    "To make the training pipeline configurable and modular, we store model parameters like number of LSTM layers, hidden size, and learning rate etc in a YAML file. This structure enables quick adaptation to related tasks B, and C.\n",
    "\n",
    "This section loads the model configuration using a custom utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc007882-2f6c-4e2e-9a19-18eb3a3dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5efd2eb-0415-43c9-ba38-492a135899d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "utils.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51de20a8-e68c-40e3-b17b-f2cc330329ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "model_config_path = os.path.join(project_root_dir, 'config', 'model_config.yaml')\n",
    "model_config = utils.read_yaml_file(model_config_path)\n",
    "# print(json.dumps(model_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db000b-c161-4faf-b555-80a64696bed4",
   "metadata": {},
   "source": [
    "## Load and Split Dataset for Training and Evaluation\n",
    "\n",
    "In this section, we load the recordings data from disk, generate data-label pairs, and split them into training and test sets according to the `test_size` defined in the YAML file.\n",
    "\n",
    "Using `test_size` and `seed` from the YAML config ensures that experiments are reproducible and easily tunable for other tasks by simply updating the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4c30c2-fdc9-4d1f-8491-8948e8a844c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = model_config['dataset']['path']\n",
    "test_data_size = model_config['data_splitting']['test_size']\n",
    "seed = model_config['experiment']['seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2e678e-b078-4b6d-8788-4807fc2912a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_pairs, calibration_samples = utils.prepare_data_label_pairs(data_path, calibration_samples_per_class=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39326a52-6342-4b71-a59c-c687ac5a0005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(calibration_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b6e981-6360-4c48-bf87-4d722523a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data_label_pairs, test_size=test_data_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8a06f-d118-462d-987e-c5ee7363933c",
   "metadata": {},
   "source": [
    "## Transform Raw Data into PyTorch Dataset Objects\n",
    "\n",
    "The `AudioFeaturesDataset` class converts raw data-label pairs into PyTorch-compatible datasets that provide easy access to samples and labels.\n",
    "\n",
    "AudioFeaturesDataset is a custom dataset class that:\n",
    "\n",
    "- Loads audio recordings of spoken digits along with their labels.\n",
    "- Optionally cleans the audio by filtering out noise.\n",
    "- Extracts MFCC features (a common speech feature).\n",
    "- Pads or trims these features to a fixed length so all inputs have the same shape.\n",
    "- Works with PyTorch to provide samples one-by-one when training or testing a model.\n",
    "- It helps prepare your audio data in the right format for training neural networks efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a181bb-fce0-4dc5-aba6-b0cc522854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import AudioFeaturesDataset\n",
    "\n",
    "train_dataset = AudioFeaturesDataset(train_data)\n",
    "test_dataset = AudioFeaturesDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4121f284-fd0e-49aa-a47b-ebfde0f1e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2400\n",
      "Test size: 600\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682500e-8660-481b-a3a8-823d4e824486",
   "metadata": {},
   "source": [
    "## Create DataLoaders for Batch Processing\n",
    "\n",
    "Using PyTorch DataLoaders, we enable efficient loading, batching, and shuffling of data during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2957cdf-bee7-4877-87c8-c4eeb186b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a30ecd48-25db-4e42-92e7-173fd8894e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = model_config['model']['input_dim']\n",
    "hidden_dim = model_config['model']['hidden_dim']\n",
    "num_layers = model_config['model']['num_layers']\n",
    "output_dim = model_config['model']['output_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6a3b93e-82ab-4347-99ef-5be89844a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29cc61-758b-4310-bc8a-8d2a0513449f",
   "metadata": {},
   "source": [
    "## Power of 2 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cbcce1b9-ded8-4bcb-a57a-3fb4e7975aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model as model\n",
    "\n",
    "hidden_dim = 24\n",
    "po2_model = model.LSTMClassifier(input_dim=input_dim,\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       num_layers=num_layers,\n",
    "                       output_dim=output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9bc6c82b-ae04-4c45-9114-45b20908b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_quant_model_load_path = os.path.join(project_root_dir, 'outputs', 'models', 'task-b-part-2_weights_jit.pth')\n",
    "\n",
    "po_model = torch.jit.load(static_quant_model_load_path)\n",
    "# po_model = torch.jit.freeze(po_model)\n",
    "\n",
    "# po2_model.load_state_dict(torch.load(static_quant_model_load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c557645b-3ae1-472b-90ce-d632e4ac8476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=StaticQuantizableModel\n",
       "  (quant): RecursiveScriptModule(original_name=Quantize)\n",
       "  (dequant): RecursiveScriptModule(original_name=DeQuantize)\n",
       "  (model): RecursiveScriptModule(\n",
       "    original_name=LSTMClassifier\n",
       "    (lstm): RecursiveScriptModule(\n",
       "      original_name=LSTM\n",
       "      (layers): RecursiveScriptModule(\n",
       "        original_name=ModuleList\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=_LSTMLayer\n",
       "          (layer_fw): RecursiveScriptModule(\n",
       "            original_name=_LSTMSingleLayer\n",
       "            (cell): RecursiveScriptModule(\n",
       "              original_name=LSTMCell\n",
       "              (igates): RecursiveScriptModule(\n",
       "                original_name=Linear\n",
       "                (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n",
       "              )\n",
       "              (hgates): RecursiveScriptModule(\n",
       "                original_name=Linear\n",
       "                (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n",
       "              )\n",
       "              (gates): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "              (input_gate): RecursiveScriptModule(original_name=Sigmoid)\n",
       "              (forget_gate): RecursiveScriptModule(original_name=Sigmoid)\n",
       "              (cell_gate): RecursiveScriptModule(original_name=Tanh)\n",
       "              (output_gate): RecursiveScriptModule(original_name=Sigmoid)\n",
       "              (fgate_cx): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "              (igate_cgate): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "              (fgate_cx_igate_cgate): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "              (ogate_cy): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): RecursiveScriptModule(\n",
       "          original_name=_LSTMLayer\n",
       "          (layer_fw): RecursiveScriptModule(\n",
       "            original_name=_LSTMSingleLayer\n",
       "            (cell): RecursiveScriptModule(\n",
       "              original_name=LSTMCell\n",
       "              (igates): RecursiveScriptModule(\n",
       "                original_name=Linear\n",
       "                (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n",
       "              )\n",
       "              (hgates): RecursiveScriptModule(\n",
       "                original_name=Linear\n",
       "                (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n",
       "              )\n",
       "              (gates): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "              (input_gate): RecursiveScriptModule(original_name=Sigmoid)\n",
       "              (forget_gate): RecursiveScriptModule(original_name=Sigmoid)\n",
       "              (cell_gate): RecursiveScriptModule(original_name=Tanh)\n",
       "              (output_gate): RecursiveScriptModule(original_name=Sigmoid)\n",
       "              (fgate_cx): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "              (igate_cgate): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "              (fgate_cx_igate_cgate): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "              (ogate_cy): RecursiveScriptModule(\n",
       "                original_name=QFunctional\n",
       "                (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "    (fc): RecursiveScriptModule(\n",
       "      original_name=Linear\n",
       "      (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po_model.eval()  # Set model to evaluation mode\n",
    "# print(po_model.model.lstm.layers.0.layer_fw.cell.igates.scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8ecd6db-6138-4599-a4f7-5301314b9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def round_scale_to_power_of_two(scale):\n",
    "    return float(2 ** round(np.log2(scale)))\n",
    "\n",
    "# Function to update quantized weights with new scale\n",
    "def update_quantized_weights(module: nn.Module):\n",
    "    # print(\"Inside\")\n",
    "    for name, submodule in module.named_children():\n",
    "        print(name)\n",
    "        print(submodule)\n",
    "        if isinstance(submodule, torch.nn.quantized.Linear):\n",
    "            print(\"Inside\")\n",
    "            old_wt = submodule.weight()\n",
    "            old_scale = old_wt.q_scale()\n",
    "            old_zp = old_wt.q_zero_point()\n",
    "\n",
    "            # Dequantize\n",
    "            float_wt = old_wt.dequantize()\n",
    "\n",
    "            # Round scale to nearest power of 2\n",
    "            new_scale = round_scale_to_power_of_two(old_scale)\n",
    "\n",
    "            # Requantize with new scale\n",
    "            new_qweight = torch.quantize_per_tensor(float_wt, scale=new_scale, zero_point=old_zp, dtype=torch.qint8)\n",
    "\n",
    "            # Replace weight\n",
    "            submodule.set_weight_bias(new_qweight, submodule.bias())\n",
    "\n",
    "            print(f\"[Updated] {name}: scale {old_scale:.6f} → {new_scale:.6f}, zero_point = {old_zp}\")\n",
    "\n",
    "        else:\n",
    "            update_quantized_weights(submodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99c8ee83-1066-4fda-ba37-58fc0a163c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Updating quantized weights to use power-of-2 scales...\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Updating quantized weights to use power-of-2 scales...\")\n",
    "update_quantized_weights(po_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2e46b-9a22-4ea2-9fb5-4fbc4c592b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spectgramer)",
   "language": "python",
   "name": "innatera-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
