{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074e24f9-a286-43cd-965b-1c41044ee99b",
   "metadata": {},
   "source": [
    "# LSTM for Spoken Digit Classification\n",
    "\n",
    "This notebook builds and trains a recurrent neural network (LSTM) to classify spoken digits (0–9) from audio recordings.\n",
    "\n",
    "- Dataset: [Free Spoken Digit Dataset (FSDD)](https://github.com/Jakobovski/free-spoken-digit-dataset)\n",
    "- Framework: PyTorch\n",
    "- Architecture: RNN with LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac121864-dea8-4206-b0d1-1acbdc0002dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root (parent of current folder) to Python path\n",
    "project_root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907bf1a-f498-4c4b-941a-1ec9859a6dbc",
   "metadata": {},
   "source": [
    "## Load Model Configuration from YAML\n",
    "\n",
    "To make the training pipeline configurable and modular, we store model parameters like number of LSTM layers, hidden size, and learning rate etc in a YAML file. This structure enables quick adaptation to related tasks B, and C.\n",
    "\n",
    "This section loads the model configuration using a custom utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc007882-2f6c-4e2e-9a19-18eb3a3dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5efd2eb-0415-43c9-ba38-492a135899d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "utils.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51de20a8-e68c-40e3-b17b-f2cc330329ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "model_config_path = os.path.join(project_root_dir, 'config', 'model_config.yaml')\n",
    "model_config = utils.read_yaml_file(model_config_path)\n",
    "# print(json.dumps(model_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db000b-c161-4faf-b555-80a64696bed4",
   "metadata": {},
   "source": [
    "## Load and Split Dataset for Training and Evaluation\n",
    "\n",
    "In this section, we load the recordings data from disk, generate data-label pairs, and split them into training and test sets according to the `test_size` defined in the YAML file.\n",
    "\n",
    "Using `test_size` and `seed` from the YAML config ensures that experiments are reproducible and easily tunable for other tasks by simply updating the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd4c30c2-fdc9-4d1f-8491-8948e8a844c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = model_config['dataset']['path']\n",
    "test_data_size = model_config['data_splitting']['test_size']\n",
    "seed = model_config['experiment']['seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f2e678e-b078-4b6d-8788-4807fc2912a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_pairs = utils.prepare_data_label_pairs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5b6e981-6360-4c48-bf87-4d722523a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data_label_pairs, test_size=test_data_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8a06f-d118-462d-987e-c5ee7363933c",
   "metadata": {},
   "source": [
    "## Transform Raw Data into PyTorch Dataset Objects\n",
    "\n",
    "The `AudioFeaturesDataset` class converts raw data-label pairs into PyTorch-compatible datasets that provide easy access to samples and labels.\n",
    "\n",
    "AudioFeaturesDataset is a custom dataset class that:\n",
    "\n",
    "- Loads audio recordings of spoken digits along with their labels.\n",
    "- Optionally cleans the audio by filtering out noise.\n",
    "- Extracts MFCC features (a common speech feature).\n",
    "- Pads or trims these features to a fixed length so all inputs have the same shape.\n",
    "- Works with PyTorch to provide samples one-by-one when training or testing a model.\n",
    "- It helps prepare your audio data in the right format for training neural networks efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7a181bb-fce0-4dc5-aba6-b0cc522854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import AudioFeaturesDataset\n",
    "\n",
    "train_dataset = AudioFeaturesDataset(train_data)\n",
    "test_dataset = AudioFeaturesDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4121f284-fd0e-49aa-a47b-ebfde0f1e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2400\n",
      "Test size: 600\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682500e-8660-481b-a3a8-823d4e824486",
   "metadata": {},
   "source": [
    "## Create DataLoaders for Batch Processing\n",
    "\n",
    "Using PyTorch DataLoaders, we enable efficient loading, batching, and shuffling of data during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2957cdf-bee7-4877-87c8-c4eeb186b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f7c9b-69cc-4239-837f-c1c82e9f3695",
   "metadata": {},
   "source": [
    "## LSTM Model Definition\n",
    "\n",
    "A simple `n`-layer LSTM followed by a fully connected output layer. Variable `n` is defined in the configuration YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a30ecd48-25db-4e42-92e7-173fd8894e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = model_config['model']['input_dim']\n",
    "hidden_dim = model_config['model']['hidden_dim']\n",
    "num_layers = model_config['model']['num_layers']\n",
    "output_dim = model_config['model']['output_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6a3b93e-82ab-4347-99ef-5be89844a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acc6726e-a78c-4846-900e-d1f38377c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model as model\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = model.LSTMClassifier(input_dim=input_dim,\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       num_layers=num_layers,\n",
    "                       output_dim=output_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b334d1-1991-454e-9b55-4621c7c63362",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b4bcea8-c7ff-46d4-b391-78c08e05adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = model_config['training']['learning_rate']\n",
    "epochs = model_config['training']['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59d97af0-0fa0-44c6-a66e-68805db8fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import ModelTrainer\n",
    "trainer_instance = ModelTrainer(\n",
    "    model, \n",
    "    epochs,\n",
    "    train_loader,\n",
    "    device,\n",
    "    learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93e3b2c-3a36-4320-99a8-4ec297bd853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 134.0127, Accuracy: 57.67%\n",
      "Epoch [2/20], Loss: 49.1018, Accuracy: 86.17%\n",
      "Epoch [3/20], Loss: 21.3893, Accuracy: 96.75%\n",
      "Epoch [4/20], Loss: 12.2558, Accuracy: 96.42%\n",
      "Epoch [5/20], Loss: 9.3282, Accuracy: 98.12%\n",
      "Epoch [6/20], Loss: 6.7593, Accuracy: 96.42%\n",
      "Epoch [7/20], Loss: 5.2892, Accuracy: 98.58%\n",
      "Epoch [8/20], Loss: 4.0651, Accuracy: 99.17%\n",
      "Epoch [9/20], Loss: 1.7189, Accuracy: 99.33%\n",
      "Epoch [10/20], Loss: 1.9559, Accuracy: 99.79%\n",
      "Epoch [11/20], Loss: 3.8065, Accuracy: 95.79%\n",
      "Epoch [12/20], Loss: 3.7462, Accuracy: 99.79%\n",
      "Epoch [13/20], Loss: 1.1268, Accuracy: 99.79%\n",
      "Epoch [14/20], Loss: 1.7250, Accuracy: 99.08%\n",
      "Epoch [15/20], Loss: 2.5933, Accuracy: 99.62%\n",
      "Epoch [16/20], Loss: 2.1036, Accuracy: 99.25%\n",
      "Epoch [17/20], Loss: 1.4843, Accuracy: 99.67%\n",
      "Epoch [18/20], Loss: 0.4845, Accuracy: 99.92%\n",
      "Epoch [19/20], Loss: 0.8350, Accuracy: 100.00%\n",
      "Epoch [20/20], Loss: 0.1467, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "trainer_instance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd17cd3-e337-43b2-b8fd-08297ef05941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer-wise parameter counts:\n",
      "lstm.weight_ih_l0              -> 6,656 params\n",
      "lstm.weight_hh_l0              -> 65,536 params\n",
      "lstm.bias_ih_l0                -> 512 params\n",
      "lstm.bias_hh_l0                -> 512 params\n",
      "lstm.weight_ih_l1              -> 65,536 params\n",
      "lstm.weight_hh_l1              -> 65,536 params\n",
      "lstm.bias_ih_l1                -> 512 params\n",
      "lstm.bias_hh_l1                -> 512 params\n",
      "fc.weight                      -> 1,280 params\n",
      "fc.bias                        -> 10 params\n",
      "\n",
      "\n",
      " Total Parameters: 206,602\n",
      "Estimated Memory: 807.04 KB (0.79 MB)\n"
     ]
    }
   ],
   "source": [
    "_, _ = utils.get_model_params_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc2bdbd-d9a6-45c2-8ab1-b80653358fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (lstm): LSTM(13, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e192852-2d93-484f-b4f1-69f4689d730f",
   "metadata": {},
   "source": [
    "## Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85f947da-ba60-44fc-9d7d-1554804a6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate import ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef20b9c-08b9-42c9-ae8b-93b7e7c4f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = ModelEvaluator(\n",
    "    model, \n",
    "    test_loader,\n",
    "    device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e00d21-ba5c-4cdb-986a-978ccc3d0d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy on test data: 99.17%\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        52\n",
      "           1     1.0000    1.0000    1.0000        65\n",
      "           2     0.9692    1.0000    0.9844        63\n",
      "           3     1.0000    0.9667    0.9831        60\n",
      "           4     1.0000    1.0000    1.0000        55\n",
      "           5     1.0000    0.9811    0.9905        53\n",
      "           6     1.0000    0.9846    0.9922        65\n",
      "           7     1.0000    0.9831    0.9915        59\n",
      "           8     0.9683    1.0000    0.9839        61\n",
      "           9     0.9853    1.0000    0.9926        67\n",
      "\n",
      "    accuracy                         0.9917       600\n",
      "   macro avg     0.9923    0.9915    0.9918       600\n",
      "weighted avg     0.9919    0.9917    0.9917       600\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[52  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 65  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 63  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 58  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 55  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 52  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 64  0  1  0]\n",
      " [ 0  0  1  0  0  0  0 58  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 67]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 99.16666666666667,\n",
       " 'predictions': array([6, 6, 7, 5, 4, 5, 6, 2, 9, 7, 5, 4, 5, 1, 5, 1, 0, 3, 0, 3, 8, 3,\n",
       "        7, 2, 1, 2, 9, 8, 6, 2, 8, 4, 5, 0, 4, 5, 4, 2, 8, 2, 0, 0, 6, 7,\n",
       "        4, 6, 4, 2, 6, 8, 4, 6, 0, 1, 7, 6, 7, 9, 8, 3, 5, 9, 6, 0, 7, 9,\n",
       "        9, 6, 0, 9, 8, 4, 5, 3, 8, 7, 1, 6, 1, 8, 5, 9, 8, 4, 4, 2, 5, 8,\n",
       "        6, 7, 0, 5, 0, 4, 3, 1, 7, 1, 2, 5, 9, 4, 0, 8, 7, 7, 2, 8, 4, 2,\n",
       "        2, 7, 9, 5, 9, 9, 9, 3, 0, 5, 9, 3, 9, 0, 8, 8, 5, 6, 2, 4, 5, 0,\n",
       "        1, 6, 2, 1, 8, 9, 9, 4, 6, 5, 2, 8, 4, 9, 1, 0, 3, 8, 3, 0, 4, 4,\n",
       "        2, 4, 4, 5, 9, 4, 6, 7, 7, 8, 4, 3, 7, 0, 3, 2, 7, 8, 0, 6, 7, 9,\n",
       "        4, 2, 6, 7, 0, 6, 2, 6, 1, 3, 9, 4, 8, 3, 3, 4, 4, 5, 7, 2, 0, 1,\n",
       "        3, 2, 4, 2, 2, 4, 5, 7, 0, 1, 2, 2, 9, 6, 9, 9, 0, 5, 9, 5, 6, 2,\n",
       "        3, 6, 1, 4, 5, 3, 8, 1, 3, 4, 4, 9, 4, 6, 7, 0, 7, 6, 3, 9, 1, 5,\n",
       "        6, 4, 9, 8, 7, 4, 6, 4, 3, 6, 3, 8, 8, 9, 8, 8, 9, 7, 9, 0, 5, 5,\n",
       "        4, 3, 3, 0, 3, 2, 8, 4, 0, 8, 7, 8, 2, 1, 5, 8, 1, 4, 6, 5, 0, 8,\n",
       "        1, 6, 7, 4, 6, 2, 6, 9, 7, 6, 1, 5, 8, 9, 8, 7, 3, 2, 2, 4, 3, 7,\n",
       "        8, 9, 8, 2, 9, 6, 9, 3, 9, 0, 2, 9, 8, 3, 6, 0, 3, 9, 0, 9, 3, 8,\n",
       "        0, 8, 3, 1, 2, 5, 9, 2, 2, 7, 5, 0, 0, 1, 5, 7, 3, 5, 6, 3, 2, 3,\n",
       "        2, 1, 1, 2, 1, 5, 3, 3, 8, 2, 8, 3, 4, 8, 5, 1, 6, 9, 0, 3, 2, 6,\n",
       "        9, 1, 5, 7, 6, 7, 3, 2, 4, 0, 7, 2, 8, 8, 3, 5, 8, 7, 9, 8, 7, 5,\n",
       "        9, 1, 0, 8, 7, 9, 8, 7, 7, 2, 9, 7, 4, 6, 4, 4, 2, 1, 3, 4, 1, 6,\n",
       "        1, 1, 3, 3, 7, 1, 7, 9, 7, 3, 1, 2, 0, 3, 5, 5, 1, 7, 0, 9, 9, 5,\n",
       "        7, 9, 6, 9, 4, 6, 8, 7, 2, 2, 8, 6, 4, 2, 9, 9, 3, 9, 7, 8, 1, 5,\n",
       "        1, 3, 8, 3, 1, 2, 1, 9, 3, 7, 6, 2, 1, 1, 3, 5, 3, 0, 0, 6, 6, 6,\n",
       "        6, 1, 8, 3, 8, 9, 6, 9, 7, 6, 6, 8, 1, 1, 5, 1, 6, 3, 1, 1, 0, 0,\n",
       "        0, 2, 6, 3, 1, 1, 0, 9, 5, 7, 9, 1, 8, 0, 9, 9, 7, 1, 1, 1, 8, 2,\n",
       "        9, 7, 4, 8, 0, 2, 1, 8, 2, 6, 6, 9, 0, 5, 6, 0, 1, 7, 2, 6, 2, 1,\n",
       "        5, 8, 2, 2, 1, 5, 7, 2, 6, 6, 5, 8, 1, 9, 7, 7, 9, 6, 5, 4, 4, 7,\n",
       "        4, 3, 5, 4, 6, 1, 1, 1, 0, 3, 0, 1, 4, 0, 1, 6, 9, 2, 8, 2, 2, 2,\n",
       "        8, 1, 3, 2, 9, 0]),\n",
       " 'labels': array([6, 6, 7, 5, 4, 5, 6, 2, 5, 7, 5, 4, 5, 1, 5, 1, 0, 3, 0, 3, 8, 3,\n",
       "        7, 2, 1, 2, 9, 8, 6, 2, 8, 4, 5, 0, 4, 5, 4, 2, 8, 2, 0, 0, 6, 7,\n",
       "        4, 6, 4, 2, 6, 8, 4, 6, 0, 1, 7, 6, 7, 9, 3, 3, 5, 9, 6, 0, 7, 9,\n",
       "        9, 6, 0, 9, 8, 4, 5, 3, 8, 7, 1, 6, 1, 8, 5, 9, 8, 4, 4, 2, 5, 8,\n",
       "        6, 7, 0, 5, 0, 4, 3, 1, 7, 1, 2, 5, 9, 4, 0, 8, 7, 7, 2, 8, 4, 2,\n",
       "        2, 7, 9, 5, 9, 9, 9, 3, 0, 5, 9, 3, 9, 0, 8, 8, 5, 6, 2, 4, 5, 0,\n",
       "        1, 6, 2, 1, 8, 9, 9, 4, 6, 5, 2, 8, 4, 9, 1, 0, 3, 8, 3, 0, 4, 4,\n",
       "        2, 4, 4, 5, 9, 4, 6, 7, 7, 8, 4, 3, 7, 0, 3, 2, 7, 8, 0, 6, 7, 9,\n",
       "        4, 2, 6, 7, 0, 6, 2, 6, 1, 3, 9, 4, 8, 3, 3, 4, 4, 5, 7, 2, 0, 1,\n",
       "        3, 2, 4, 2, 2, 4, 5, 7, 0, 1, 2, 3, 9, 6, 9, 9, 0, 5, 9, 5, 6, 2,\n",
       "        3, 6, 1, 4, 5, 3, 8, 1, 3, 4, 4, 9, 4, 6, 7, 0, 7, 6, 3, 9, 1, 5,\n",
       "        6, 4, 9, 8, 7, 4, 6, 4, 3, 6, 3, 8, 8, 9, 8, 8, 9, 7, 9, 0, 5, 5,\n",
       "        4, 3, 3, 0, 3, 7, 8, 4, 0, 8, 7, 8, 2, 1, 5, 8, 1, 4, 6, 5, 0, 8,\n",
       "        1, 6, 7, 4, 6, 2, 6, 9, 7, 6, 1, 5, 8, 9, 8, 7, 3, 2, 2, 4, 3, 7,\n",
       "        8, 9, 8, 2, 9, 6, 9, 3, 9, 0, 2, 9, 8, 3, 6, 0, 3, 9, 0, 9, 3, 8,\n",
       "        0, 8, 3, 1, 2, 5, 9, 2, 2, 7, 5, 0, 0, 1, 5, 7, 3, 5, 6, 3, 2, 3,\n",
       "        2, 1, 1, 2, 1, 5, 3, 3, 8, 2, 8, 3, 4, 8, 5, 1, 6, 9, 0, 3, 2, 6,\n",
       "        9, 1, 5, 7, 6, 7, 3, 2, 4, 0, 7, 2, 6, 8, 3, 5, 8, 7, 9, 8, 7, 5,\n",
       "        9, 1, 0, 8, 7, 9, 8, 7, 7, 2, 9, 7, 4, 6, 4, 4, 2, 1, 3, 4, 1, 6,\n",
       "        1, 1, 3, 3, 7, 1, 7, 9, 7, 3, 1, 2, 0, 3, 5, 5, 1, 7, 0, 9, 9, 5,\n",
       "        7, 9, 6, 9, 4, 6, 8, 7, 2, 2, 8, 6, 4, 2, 9, 9, 3, 9, 7, 8, 1, 5,\n",
       "        1, 3, 8, 3, 1, 2, 1, 9, 3, 7, 6, 2, 1, 1, 3, 5, 3, 0, 0, 6, 6, 6,\n",
       "        6, 1, 8, 3, 8, 9, 6, 9, 7, 6, 6, 8, 1, 1, 5, 1, 6, 3, 1, 1, 0, 0,\n",
       "        0, 2, 6, 3, 1, 1, 0, 9, 5, 7, 9, 1, 8, 0, 9, 9, 7, 1, 1, 1, 8, 2,\n",
       "        9, 7, 4, 8, 0, 2, 1, 8, 2, 6, 6, 9, 0, 5, 6, 0, 1, 7, 2, 6, 2, 1,\n",
       "        5, 8, 2, 2, 1, 5, 7, 2, 6, 6, 5, 8, 1, 9, 7, 7, 9, 6, 5, 4, 4, 7,\n",
       "        4, 3, 5, 4, 6, 1, 1, 1, 0, 3, 0, 1, 4, 0, 1, 6, 9, 2, 8, 2, 2, 2,\n",
       "        8, 1, 3, 2, 9, 0])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_instance.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863b267-4316-4fe2-8a49-72d03ea4fbd3",
   "metadata": {},
   "source": [
    "## Task B — Retrain Under Memory Constraints\n",
    "\n",
    "- All parameters of any one layer must fit into memory simultaneously\n",
    "- Maximum memory available for layer parameters is 36 KB\n",
    "\n",
    "Since Pytorch stores all the layer parameters as floating point values, as 32-bit floats(4 bytes per parameter), this implies that the \n",
    "maximum number of parameters should not exceed\n",
    "\n",
    "$$\n",
    "\\text{Max total number of parameters} = \\frac{36\\,\\text{KB}}{4\\,\\text{bytes}} = \\frac{36 \\times 1024}{4} = 9,216 \\text{ parameters}\n",
    "$$\n",
    "\n",
    "## Model Parameter Breakdown for 2 Layers LSTM\n",
    "The following calculations are based on the parameter definitions from PyTorch's LSTM implementation, as described in the \\href{https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html\\#torch.nn.LSTM}{official documentation}. \n",
    "\n",
    "Let’s define the following variables:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Input dimension} &= i \\\\\n",
    "\\text{Hidden dimension} &= h \\\\\n",
    "\\text{Output dimension} &= o \\\\\n",
    "\\text{Number of LSTM layers} &= 2 \\\\\n",
    "\\text{Fully Connected (Linear) layer count} &= 1 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "These will be used to calculate the total number of parameters in the model.\n",
    "\n",
    "---\n",
    "\n",
    "## LSTM Layer Parameters\n",
    "\n",
    "Each LSTM layer has 4 internal gates (input, forget, cell, output).  \n",
    "So each layer has:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W\\_{ih} &: \\text{Weights from input to hidden} \\rightarrow \\text{shape: } (4 \\times h, i) \\\\\n",
    "W\\_{hh} &: \\text{Weights from hidden to hidden} \\rightarrow \\text{shape: } (4 \\times h, h) \\\\\n",
    "b\\_{ih}, b\\_{hh} &: \\text{Biases for each gate} \\rightarrow \\text{shape: } (4 \\times h)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Calculations:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\textbf{Layer 1 Parameters} \\\\\n",
    "&W\\_ih: 4 \\times h \\times i \\\\\n",
    "&W\\_hh: 4 \\times h \\times h \\\\\n",
    "&b\\_ih: 4 \\times h \\\\\n",
    "&b\\_hh: 4 \\times h \\\\\n",
    "&\\\\\n",
    "&\\textbf{Layer 2 Parameters} \\\\\n",
    "&W\\_ih: 4 \\times h \\times h \\\\\n",
    "&W\\_hh: 4 \\times h \\times h \\\\\n",
    "&b\\_ih: 4 \\times h \\\\\n",
    "&b\\_hh: 4 \\times h \\\\\n",
    "&\\\\\n",
    "&\\text{Total LSTM parameters} = (4 \\times h \\times i) + (4 \\times h \\times h) + (8 \\times h) = 4hi + 4h^2 + 8h\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Fully Connected (Linear) Layer\n",
    "\n",
    "- Input features = $$\\text{hidden\\_dim} = h$$  \n",
    "- Output features = $$\\text{output\\_dim} = o$$\n",
    "\n",
    "### Calculations:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{Weights}: \\quad h \\times o \\\\\n",
    "&\\text{Bias}: \\quad o \\\\\n",
    "&\\textbf{Total Linear parameters} = h \\cdot o + o = o(h + 1)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Total Parameters\n",
    "\n",
    "The total number of parameters in the model is the sum of the LSTM and Linear layer parameters:\n",
    "\n",
    "$$\n",
    "\\text{Total Parameters} = \\text{Total LSTM Parameters} + \\text{Total Linear Parameters}\n",
    "$$\n",
    "\n",
    "From earlier calculations:\n",
    "\n",
    "- $\\text{Total LSTM Parameters} = 4hi + 4h^2 + 8h$\n",
    "- $\\text{Total Linear Parameters} = h \\cdot o + o = o(h + 1)$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "\\text{Total Parameters} = (4hi + 4h^2 + 8h) + o(h + 1)\n",
    "$$\n",
    "\n",
    "Or more compactly:\n",
    "\n",
    "$$\n",
    "\\boxed{\\text{Total Parameters} = 4hi + 4h^2 + 8h + o(h + 1)}\n",
    "$$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958d7b7-41d4-4753-99c0-42ae9303be61",
   "metadata": {},
   "source": [
    "## Designing a 2-Layer LSTM Under a 36 KB Memory Constraint\n",
    "\n",
    "Given an output dimension of $10$ (representing 10 classes or digits) and an input dimension of $13$ (corresponding to 13 MFCC coefficients per time step), the total number of parameters in the model reduces to the following quadratic expression:\n",
    "\n",
    "$$\n",
    "\\text{Total Parameters} = 12h^2 + 78h + 10\n",
    "$$\n",
    "\n",
    "Here, $ h $ (the hidden dimension) remains the only variable we need to solve for.\n",
    "\n",
    "Since the memory constraint allows for a maximum of \\textbf{9,216 parameters}, the hidden dimension must satisfy:\n",
    "\n",
    "$$\n",
    "12h^2 + 78h + 10 \\leq 9216\n",
    "$$\n",
    "\n",
    "The maximum valid integer value of $ h $ that satisfies the inequality is:\n",
    "$$\n",
    "h = 24\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92bbbd4b-4632-472a-885e-2e07f1894c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model as model_with_constraints\n",
    "\n",
    "hidden_dim = 24\n",
    "two_layer_model_with_constraints = model_with_constraints.LSTMClassifier(input_dim=input_dim,\n",
    "                                           hidden_dim=hidden_dim,\n",
    "                                           num_layers=num_layers,\n",
    "                                           output_dim=output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf734e3a-c8ec-4df5-98e8-22a38e69674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import ModelTrainer\n",
    "trainer_instance = ModelTrainer(\n",
    "    two_layer_model_with_constraints, \n",
    "    epochs,\n",
    "    train_loader,\n",
    "    device,\n",
    "    learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16108f19-ba8a-42ee-85fd-d8b9dc257643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 172.2554, Accuracy: 18.17%\n",
      "Epoch [2/20], Loss: 141.0399, Accuracy: 32.17%\n",
      "Epoch [3/20], Loss: 106.1623, Accuracy: 52.29%\n",
      "Epoch [4/20], Loss: 90.3998, Accuracy: 59.21%\n",
      "Epoch [5/20], Loss: 78.1598, Accuracy: 64.83%\n",
      "Epoch [6/20], Loss: 69.3477, Accuracy: 73.33%\n",
      "Epoch [7/20], Loss: 58.6390, Accuracy: 76.50%\n",
      "Epoch [8/20], Loss: 51.9842, Accuracy: 79.42%\n",
      "Epoch [9/20], Loss: 47.4075, Accuracy: 81.67%\n",
      "Epoch [10/20], Loss: 38.8978, Accuracy: 84.08%\n",
      "Epoch [11/20], Loss: 37.5306, Accuracy: 84.50%\n",
      "Epoch [12/20], Loss: 35.1007, Accuracy: 87.12%\n",
      "Epoch [13/20], Loss: 29.0342, Accuracy: 90.62%\n",
      "Epoch [14/20], Loss: 26.8872, Accuracy: 91.21%\n",
      "Epoch [15/20], Loss: 22.7544, Accuracy: 93.92%\n",
      "Epoch [16/20], Loss: 19.4326, Accuracy: 94.58%\n",
      "Epoch [17/20], Loss: 17.7522, Accuracy: 95.67%\n",
      "Epoch [18/20], Loss: 15.5943, Accuracy: 96.08%\n",
      "Epoch [19/20], Loss: 14.5663, Accuracy: 95.08%\n",
      "Epoch [20/20], Loss: 13.6361, Accuracy: 96.79%\n"
     ]
    }
   ],
   "source": [
    "trainer_instance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ad2f6cf-3eb9-48c2-9152-7843f556a770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer-wise parameter counts:\n",
      "lstm.weight_ih_l0              -> 1,248 params\n",
      "lstm.weight_hh_l0              -> 2,304 params\n",
      "lstm.bias_ih_l0                -> 96 params\n",
      "lstm.bias_hh_l0                -> 96 params\n",
      "lstm.weight_ih_l1              -> 2,304 params\n",
      "lstm.weight_hh_l1              -> 2,304 params\n",
      "lstm.bias_ih_l1                -> 96 params\n",
      "lstm.bias_hh_l1                -> 96 params\n",
      "fc.weight                      -> 240 params\n",
      "fc.bias                        -> 10 params\n",
      "\n",
      "\n",
      " Total Parameters: 8,794\n",
      "Estimated Memory: 34.35 KB (0.03 MB)\n"
     ]
    }
   ],
   "source": [
    "_, _ = utils.get_model_params_size(two_layer_model_with_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bace95f-b096-4648-baf2-2bdc0375f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate import ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91968fee-a54e-40ba-a2ed-1ba2d1039615",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = ModelEvaluator(\n",
    "    two_layer_model_with_constraints, \n",
    "    test_loader,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4352fe35-66bc-4cf1-8bd3-d129e20617e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy on test data: 93.67%\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9800    0.9423    0.9608        52\n",
      "           1     1.0000    0.9538    0.9764        65\n",
      "           2     0.8857    0.9841    0.9323        63\n",
      "           3     0.9811    0.8667    0.9204        60\n",
      "           4     0.9821    1.0000    0.9910        55\n",
      "           5     0.8966    0.9811    0.9369        53\n",
      "           6     0.8889    0.8615    0.8750        65\n",
      "           7     0.9825    0.9492    0.9655        59\n",
      "           8     0.8507    0.9344    0.8906        61\n",
      "           9     0.9531    0.9104    0.9313        67\n",
      "\n",
      "    accuracy                         0.9367       600\n",
      "   macro avg     0.9401    0.9384    0.9380       600\n",
      "weighted avg     0.9394    0.9367    0.9369       600\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[49  0  2  0  0  0  0  1  0  0]\n",
      " [ 0 62  1  0  0  2  0  0  0  0]\n",
      " [ 0  0 62  0  0  0  0  0  0  1]\n",
      " [ 0  0  3 52  0  0  2  0  2  1]\n",
      " [ 0  0  0  0 55  0  0  0  0  0]\n",
      " [ 0  0  0  0  1 52  0  0  0  0]\n",
      " [ 0  0  0  1  0  0 56  0  8  0]\n",
      " [ 1  0  0  0  0  0  1 56  0  1]\n",
      " [ 0  0  0  0  0  0  4  0 57  0]\n",
      " [ 0  0  2  0  0  4  0  0  0 61]]\n"
     ]
    }
   ],
   "source": [
    "test_instance.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab758217-b57a-4f62-91e0-4576df4af82e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4fd5d7-b633-4659-8782-d071a75553af",
   "metadata": {},
   "source": [
    "## Floating Point Restriction (Task B Continued)\n",
    "\n",
    "In addition to the 36 KB memory constraint, the hardware for Task B is limited in computational capability and **does not support floating point operations**. It means the network must operate using **integer or fixed-point arithmetic** only. **Weights, activations, and computations** should be **quantized** to lower-precision formats such as 8-bit integers (INT8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65bbcbb6-07e7-432e-bf04-d56cf0d20471",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_model_with_constraints_cpu = two_layer_model_with_constraints.to('cpu') \n",
    "# Apply dynamic quantization to the entire model or just LSTM/Linear layers\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    two_layer_model_with_constraints_cpu,  # the model instance\n",
    "    {nn.LSTM, nn.Linear},  # layers to quantize\n",
    "    dtype=torch.qint8  # quantize to 8-bit integers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40d46328-0968-47c0-a43e-fa9c9cd95d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate import ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ed358da-c959-47ba-b90e-1dac930cf08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "test_instance = ModelEvaluator(\n",
    "    quantized_model, \n",
    "    test_loader,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cde78786-f9d9-4f73-a478-77e46158c359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy on test data: 93.50%\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9800    0.9423    0.9608        52\n",
      "           1     1.0000    0.9385    0.9683        65\n",
      "           2     0.8732    0.9841    0.9254        63\n",
      "           3     0.9811    0.8667    0.9204        60\n",
      "           4     0.9821    1.0000    0.9910        55\n",
      "           5     0.8814    0.9811    0.9286        53\n",
      "           6     0.8889    0.8615    0.8750        65\n",
      "           7     0.9821    0.9322    0.9565        59\n",
      "           8     0.8507    0.9344    0.8906        61\n",
      "           9     0.9688    0.9254    0.9466        67\n",
      "\n",
      "    accuracy                         0.9350       600\n",
      "   macro avg     0.9388    0.9366    0.9363       600\n",
      "weighted avg     0.9385    0.9350    0.9353       600\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[49  0  2  0  0  0  0  1  0  0]\n",
      " [ 0 61  1  0  0  3  0  0  0  0]\n",
      " [ 0  0 62  0  0  0  0  0  0  1]\n",
      " [ 0  0  4 52  0  0  2  0  2  0]\n",
      " [ 0  0  0  0 55  0  0  0  0  0]\n",
      " [ 0  0  0  0  1 52  0  0  0  0]\n",
      " [ 0  0  0  1  0  0 56  0  8  0]\n",
      " [ 1  0  1  0  0  0  1 55  0  1]\n",
      " [ 0  0  0  0  0  0  4  0 57  0]\n",
      " [ 0  0  1  0  0  4  0  0  0 62]]\n"
     ]
    }
   ],
   "source": [
    "test_instance.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604a3fe-3e65-4262-88ff-010ab7bf4a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909dfeee-ae80-427c-af86-ab8fb13ca359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545160c5-ce11-4412-8fcb-687c711d3464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfe0dd-e157-48aa-b670-6864307591e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df73ae4-aa64-4a8d-9abe-bf1b8146d8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a50dc-83e1-47e0-8ff3-6c2737338069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dbbef6-8eac-4ae4-9c47-42c5088e6946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d1b42-cdcf-43db-b4e3-8e2c3dbc3120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58bd6058-17dd-43e8-85d7-35c31190adab",
   "metadata": {},
   "source": [
    "## Total Parameters for 1-Layer LSTM\n",
    "\n",
    "For a single LSTM layer, with the same input and output dimensions (13 MFCC coefficients and 10 output classes), the total number of parameters simplifies to:\n",
    "\n",
    "$$\n",
    "\\text{Total Parameters} = 4h^2 + 70h + 10\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d68ab-da15-49de-be24-b6c5b3d58a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spectgramer)",
   "language": "python",
   "name": "innatera-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
