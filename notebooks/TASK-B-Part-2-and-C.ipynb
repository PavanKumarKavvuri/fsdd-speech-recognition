{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074e24f9-a286-43cd-965b-1c41044ee99b",
   "metadata": {},
   "source": [
    "# Task B: Part-2 : Int8 Quantization and\n",
    "# Task C: Power of 2 Quantisation\n",
    "\n",
    "This notebook builds and trains a recurrent neural network (LSTM) to classify spoken digits (0â€“9) from audio recordings.\n",
    "\n",
    "- Dataset: [Free Spoken Digit Dataset (FSDD)](https://github.com/Jakobovski/free-spoken-digit-dataset)\n",
    "- Framework: PyTorch\n",
    "- Architecture: RNN with LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac121864-dea8-4206-b0d1-1acbdc0002dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root (parent of current folder) to Python path\n",
    "project_root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907bf1a-f498-4c4b-941a-1ec9859a6dbc",
   "metadata": {},
   "source": [
    "## Load Model Configuration from YAML\n",
    "\n",
    "To make the training pipeline configurable and modular, we store model parameters like number of LSTM layers, hidden size, and learning rate etc in a YAML file. This structure enables quick adaptation to related tasks B, and C.\n",
    "\n",
    "This section loads the model configuration using a custom utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc007882-2f6c-4e2e-9a19-18eb3a3dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5efd2eb-0415-43c9-ba38-492a135899d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "utils.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51de20a8-e68c-40e3-b17b-f2cc330329ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "model_config_path = os.path.join(project_root_dir, 'config', 'model_config.yaml')\n",
    "model_config = utils.read_yaml_file(model_config_path)\n",
    "# print(json.dumps(model_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db000b-c161-4faf-b555-80a64696bed4",
   "metadata": {},
   "source": [
    "## Load and Split Dataset for Training and Evaluation\n",
    "\n",
    "In this section, we load the recordings data from disk, generate data-label pairs, and split them into training and test sets according to the `test_size` defined in the YAML file.\n",
    "\n",
    "Using `test_size` and `seed` from the YAML config ensures that experiments are reproducible and easily tunable for other tasks by simply updating the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4c30c2-fdc9-4d1f-8491-8948e8a844c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = model_config['dataset']['path']\n",
    "test_data_size = model_config['data_splitting']['test_size']\n",
    "seed = model_config['experiment']['seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2e678e-b078-4b6d-8788-4807fc2912a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_pairs, calibration_samples = utils.prepare_data_label_pairs(data_path, calibration_samples_per_class=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39326a52-6342-4b71-a59c-c687ac5a0005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(calibration_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b6e981-6360-4c48-bf87-4d722523a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data_label_pairs, test_size=test_data_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8a06f-d118-462d-987e-c5ee7363933c",
   "metadata": {},
   "source": [
    "## Transform Raw Data into PyTorch Dataset Objects\n",
    "\n",
    "The `AudioFeaturesDataset` class converts raw data-label pairs into PyTorch-compatible datasets that provide easy access to samples and labels.\n",
    "\n",
    "AudioFeaturesDataset is a custom dataset class that:\n",
    "\n",
    "- Loads audio recordings of spoken digits along with their labels.\n",
    "- Optionally cleans the audio by filtering out noise.\n",
    "- Extracts MFCC features (a common speech feature).\n",
    "- Pads or trims these features to a fixed length so all inputs have the same shape.\n",
    "- Works with PyTorch to provide samples one-by-one when training or testing a model.\n",
    "- It helps prepare your audio data in the right format for training neural networks efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a181bb-fce0-4dc5-aba6-b0cc522854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import AudioFeaturesDataset\n",
    "\n",
    "train_dataset = AudioFeaturesDataset(train_data)\n",
    "test_dataset = AudioFeaturesDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4121f284-fd0e-49aa-a47b-ebfde0f1e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2400\n",
      "Test size: 600\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682500e-8660-481b-a3a8-823d4e824486",
   "metadata": {},
   "source": [
    "## Create DataLoaders for Batch Processing\n",
    "\n",
    "Using PyTorch DataLoaders, we enable efficient loading, batching, and shuffling of data during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2957cdf-bee7-4877-87c8-c4eeb186b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30ecd48-25db-4e42-92e7-173fd8894e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = model_config['model']['input_dim']\n",
    "hidden_dim = model_config['model']['hidden_dim']\n",
    "num_layers = model_config['model']['num_layers']\n",
    "output_dim = model_config['model']['output_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a3b93e-82ab-4347-99ef-5be89844a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29cc61-758b-4310-bc8a-8d2a0513449f",
   "metadata": {},
   "source": [
    "## Static Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbcce1b9-ded8-4bcb-a57a-3fb4e7975aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model as model\n",
    "\n",
    "hidden_dim = 24\n",
    "quant_model = model.LSTMClassifier(input_dim=input_dim,\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       num_layers=num_layers,\n",
    "                       output_dim=output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bc6c82b-ae04-4c45-9114-45b20908b919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_constraint_model_load_path = os.path.join(project_root_dir, 'outputs', 'models', 'task-b-part-1_weights.pth')\n",
    "quant_model.load_state_dict(torch.load(memory_constraint_model_load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c557645b-3ae1-472b-90ce-d632e4ac8476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (lstm): LSTM(13, 24, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=24, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74102fd8-de55-41a7-99d8-ff589f26527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.quantize as quantize\n",
    "static_quant_model = quantize.StaticQuantizableModel(quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0aa6bea-00c5-444c-a8f6-a832e3cb0922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavan/Music/spectrum/spectgramer/lib/python3.10/site-packages/torch/ao/quantization/observer.py:244: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/home/pavan/Music/spectrum/spectgramer/lib/python3.10/site-packages/torch/ao/nn/quantizable/modules/rnn.py:462: UserWarning: dropout option for quantizable LSTM is ignored. If you are training, please, use nn.LSTM version followed by `prepare` step.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "static_quant_model.qconfig = torch.quantization.get_default_qconfig('x86')  # For edge devices\n",
    "# torch.backends.quantized.engine = 'fbgemm'\n",
    "\n",
    "from torch.ao.quantization import MinMaxObserver, PerChannelMinMaxObserver, QConfig, MovingAverageMinMaxObserver, MovingAveragePerChannelMinMaxObserver\n",
    "qconfig = QConfig(activation=MovingAveragePerChannelMinMaxObserver.with_args(qscheme=torch.per_tensor_affine, dtype=torch.quint8),\n",
    "       weight=PerChannelMinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
    "\n",
    "static_quant_model_prepared = torch.quantization.prepare(static_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "285c2385-70b7-4c0d-945f-7d597de40cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration set size : 500\n"
     ]
    }
   ],
   "source": [
    "calibration_sampleset = AudioFeaturesDataset(calibration_samples)\n",
    "calibration_loader = torch.utils.data.DataLoader(calibration_sampleset, batch_size=32, shuffle=True)\n",
    "print(f\"Calibration set size : {len(calibration_sampleset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5440b3c5-07d9-4e5b-a71f-9a94ea7c21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_quant_model_prepared_cpu = static_quant_model_prepared.to('cpu')\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "quantize.calibrate(static_quant_model_prepared, calibration_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "702c7a4e-ca23-4526-801b-86f40fac6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_quantized_model_converted = torch.quantization.convert(static_quant_model_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0e93b23-1526-4397-b534-9365d9f9cd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from src.evaluate import ModelEvaluator\n",
    "print(device)\n",
    "quant_test_instance = ModelEvaluator(\n",
    "    static_quantized_model_converted, \n",
    "    test_loader,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81f25534-4412-4767-9d1a-a5fa96700202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavan/Music/spectrum/spectgramer/lib/python3.10/site-packages/torch/ao/nn/quantizable/modules/rnn.py:543: UserWarning: All inputs of this cat operator must share the same quantization parameters. Otherwise large numerical inaccuracies may occur. (Triggered internally at /pytorch/aten/src/ATen/native/quantized/cpu/TensorShape.cpp:167.)\n",
      "  cx_tensor = torch.stack(cx_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy on test data: 85.00%\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7907    0.9444    0.8608        72\n",
      "           1     0.9574    0.6522    0.7759        69\n",
      "           2     0.9070    0.6842    0.7800        57\n",
      "           3     0.7887    1.0000    0.8819        56\n",
      "           4     0.8750    0.9492    0.9106        59\n",
      "           5     0.9259    0.7937    0.8547        63\n",
      "           6     0.8958    0.7679    0.8269        56\n",
      "           7     0.7571    0.9636    0.8480        55\n",
      "           8     0.8727    0.8421    0.8571        57\n",
      "           9     0.8387    0.9286    0.8814        56\n",
      "\n",
      "    accuracy                         0.8500       600\n",
      "   macro avg     0.8609    0.8526    0.8477       600\n",
      "weighted avg     0.8622    0.8500    0.8468       600\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[68  0  2  1  0  0  0  0  0  1]\n",
      " [ 4 45  0  0  6  2  0 11  0  1]\n",
      " [ 8  0 39  2  0  0  0  2  0  6]\n",
      " [ 0  0  0 56  0  0  0  0  0  0]\n",
      " [ 1  1  0  0 56  0  0  1  0  0]\n",
      " [ 4  0  2  0  2 50  0  3  0  2]\n",
      " [ 0  0  0  6  0  0 43  0  7  0]\n",
      " [ 0  1  0  0  0  1  0 53  0  0]\n",
      " [ 0  0  0  4  0  0  5  0 48  0]\n",
      " [ 1  0  0  2  0  1  0  0  0 52]]\n"
     ]
    }
   ],
   "source": [
    "quant_test_instance.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd850279-2183-4a06-bf79-75612ef508bf",
   "metadata": {},
   "source": [
    "### Compute Inference TimeÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af7fa4b7-f69c-4efa-8dac-87e2de259c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median inference time: 8.7123 ms\n"
     ]
    }
   ],
   "source": [
    "utils.compute_inference_time(static_quantized_model_converted, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e10ab-9fb7-4a25-b30d-3456723198e6",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8ecd6db-6138-4599-a4f7-5301314b9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_quantized_model_converted.eval()\n",
    "\n",
    "static_quant_model_save_path = os.path.join(project_root_dir, 'outputs', 'models', 'task-b-part-2_weights_jit.pth')\n",
    "\n",
    "script_model = torch.jit.script(static_quantized_model_converted)\n",
    "torch.jit.save(script_model, static_quant_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f1c65-217b-4c0a-8789-49c223ebbd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39e930-1b1f-4cd9-bcc3-54d66b6cd854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "050d09c7-1a55-4b1d-8a77-9fc6f5ca6a0c",
   "metadata": {},
   "source": [
    "## Is the Model INT8 Quantised? Does it meet the 36 KB Memory Constraint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4c0e4bd-d360-41a8-ab5d-e861caed9ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model.lstm.layers.0.layer_fw.cell.igates is a quantized Linear layer\n",
      "Weight type: <class 'torch.Tensor'>\n",
      "Weight dtype: torch.qint8\n",
      "Weight shape: torch.Size([96, 13])\n",
      "---\n",
      "\n",
      "model.lstm.layers.0.layer_fw.cell.hgates is a quantized Linear layer\n",
      "Weight type: <class 'torch.Tensor'>\n",
      "Weight dtype: torch.qint8\n",
      "Weight shape: torch.Size([96, 24])\n",
      "---\n",
      "\n",
      "model.lstm.layers.1.layer_fw.cell.igates is a quantized Linear layer\n",
      "Weight type: <class 'torch.Tensor'>\n",
      "Weight dtype: torch.qint8\n",
      "Weight shape: torch.Size([96, 24])\n",
      "---\n",
      "\n",
      "model.lstm.layers.1.layer_fw.cell.hgates is a quantized Linear layer\n",
      "Weight type: <class 'torch.Tensor'>\n",
      "Weight dtype: torch.qint8\n",
      "Weight shape: torch.Size([96, 24])\n",
      "---\n",
      "\n",
      "model.fc is a quantized Linear layer\n",
      "Weight type: <class 'torch.Tensor'>\n",
      "Weight dtype: torch.qint8\n",
      "Weight shape: torch.Size([10, 24])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for name, module in static_quantized_model_converted.named_modules():\n",
    "    if isinstance(module, torch.nn.quantized.Linear):\n",
    "        print(f\"\\n{name} is a quantized Linear layer\")\n",
    "        weight = module.weight()\n",
    "        print(\"Weight type:\", type(weight))\n",
    "        print(\"Weight dtype:\", weight.dtype)\n",
    "        print(\"Weight shape:\", weight.shape)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d257145a-26bd-4dba-a432-846542b292c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated FP32 size: 32.81 KB\n",
      "Estimated INT8 size: 8.20 KB\n",
      "Compression ratio: 4.00x\n"
     ]
    }
   ],
   "source": [
    "total_fp32_bytes = 0\n",
    "total_int8_bytes = 0\n",
    "\n",
    "for name, module in static_quantized_model_converted.named_modules():\n",
    "    if isinstance(module, torch.nn.quantized.Linear):\n",
    "        weight = module.weight()\n",
    "        if weight.is_quantized:\n",
    "            num_elements = weight.numel()\n",
    "            total_fp32_bytes += num_elements * 4  # FP32\n",
    "            total_int8_bytes += num_elements * 1  # INT8\n",
    "\n",
    "print(f\"Estimated FP32 size: {total_fp32_bytes / 1024:.2f} KB\")\n",
    "print(f\"Estimated INT8 size: {total_int8_bytes / 1024:.2f} KB\")\n",
    "print(f\"Compression ratio: {total_fp32_bytes / total_int8_bytes:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3550aff-1b76-4659-8280-9702e58a477c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " INT8 Model - Layer Analysis\n",
      "Layer Name                               | Num Parameters | Size (INT8) | Fits in 36KB?\n",
      "---------------------------------------------------------------------------\n",
      "model.lstm.layers.0.layer_fw.cell.igates |          1248 | 1.219 KB     | âœ…\n",
      "model.lstm.layers.0.layer_fw.cell.hgates |          2304 | 2.250 KB     | âœ…\n",
      "model.lstm.layers.1.layer_fw.cell.igates |          2304 | 2.250 KB     | âœ…\n",
      "model.lstm.layers.1.layer_fw.cell.hgates |          2304 | 2.250 KB     | âœ…\n",
      "model.fc                                 |           240 | 0.234 KB     | âœ…\n",
      "\n",
      "ðŸ“¦ Total Estimated Memory Usage\n",
      "Total number of parameters:      8400\n",
      "Estimated total size (INT8):     8.203 KB\n",
      "Memory per parameter (INT8):     1 byte\n",
      "Meets 36KB per-layer limit?      âœ… Yes\n"
     ]
    }
   ],
   "source": [
    "utils.print_quantized_layer_analysis(static_quantized_model_converted, \"INT8 Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0a65c-6d8e-4d33-b8e7-ed11bf592ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620c0ad-8da3-4b3f-aae5-e76d8f6c7ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fd672-5dd0-4f31-acfe-282759721b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f7a9aac-c0bd-4625-a735-68c9a306fd67",
   "metadata": {},
   "source": [
    "## Task C: Power of 2 Quantization: Transforming only Scale factors to Powers of Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b84f90b-eaa3-4fff-92e2-0fe8c7f21c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "po2_quantized_model = copy.deepcopy(static_quantized_model_converted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5713b725-27ee-40ee-b444-50f8c609fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def round_scale_to_power_of_two(scale):\n",
    "    if scale <= 0:\n",
    "        return scale\n",
    "    return 2 ** round(math.log2(scale))\n",
    "\n",
    "def update_quantized_weights_and_show_scales(module: nn.Module):\n",
    "    for name, submodule in module.named_children():\n",
    "        if isinstance(submodule, torch.nn.quantized.Linear):\n",
    "            old_wt = submodule.weight()\n",
    "            qscheme = old_wt.qscheme()\n",
    "\n",
    "            if qscheme == torch.per_tensor_affine:\n",
    "                old_scale = old_wt.q_scale()\n",
    "                old_zp = old_wt.q_zero_point()\n",
    "                float_wt = old_wt.dequantize()\n",
    "                new_scale = round_scale_to_power_of_two(old_scale)\n",
    "                new_qweight = torch.quantize_per_tensor(\n",
    "                    float_wt, scale=new_scale, zero_point=old_zp, dtype=torch.qint8\n",
    "                )\n",
    "                submodule.set_weight_bias(new_qweight, submodule.bias())\n",
    "                print(f\"[Per-tensor] {name}:\")\n",
    "                print(f\"  Old scale: {old_scale:.8f}\")\n",
    "                print(f\"  New scale: {new_scale:.8f}\")\n",
    "                print(f\"  Zero point: {old_zp}\")\n",
    "\n",
    "            elif qscheme == torch.per_channel_affine:\n",
    "                old_scales = old_wt.q_per_channel_scales()\n",
    "                old_zps = old_wt.q_per_channel_zero_points()\n",
    "                axis = old_wt.q_per_channel_axis()\n",
    "                float_wt = old_wt.dequantize()\n",
    "                new_scales = torch.tensor(\n",
    "                    [round_scale_to_power_of_two(s.item()) for s in old_scales],\n",
    "                    dtype=old_scales.dtype,\n",
    "                    device=old_scales.device\n",
    "                )\n",
    "                new_qweight = torch.quantize_per_channel(\n",
    "                    float_wt, new_scales, old_zps, axis=axis, dtype=torch.qint8\n",
    "                )\n",
    "                submodule.set_weight_bias(new_qweight, submodule.bias())\n",
    "                print(f\"[Per-channel] {name}:\")\n",
    "                print(f\"  Old scales: {old_scales.tolist()}\")\n",
    "                print(f\"  New scales: {new_scales.tolist()}\")\n",
    "                print(f\"  Zero points: {old_zps.tolist()}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"[Skipped] {name}: Unsupported qscheme {qscheme}\")\n",
    "\n",
    "        else:\n",
    "            update_quantized_weights_and_show_scales(submodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a093e8a-7cb5-4437-b988-2d1d9b3b79a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Per-channel] igates:\n",
      "  Old scales: [0.001615653745830059, 0.0018714802572503686, 0.0020117308013141155, 0.002106273779645562, 0.0022053238935768604, 0.002103707753121853, 0.0016710897907614708, 0.002046100329607725, 0.0017540731932967901, 0.00208006682805717, 0.001712300698272884, 0.0019382458413019776, 0.0018706321716308594, 0.0017586955800652504, 0.0016365181654691696, 0.00345902843400836, 0.002487811027094722, 0.0021910173818469048, 0.0018338965019211173, 0.0013152362080290914, 0.002594183199107647, 0.002215113490819931, 0.001944198738783598, 0.0017140066483989358, 0.0021132363472133875, 0.0026520786341279745, 0.0017188069177791476, 0.002268699463456869, 0.0019005556823685765, 0.002209493424743414, 0.0021241006907075644, 0.002217937959358096, 0.001790273585356772, 0.0012400405248627067, 0.0017527616582810879, 0.0018183921929448843, 0.0016870113322511315, 0.0017570874188095331, 0.0020349151454865932, 0.0015564362984150648, 0.0017177117988467216, 0.0025220997631549835, 0.0017155376262962818, 0.0019849140662699938, 0.0018530812812969089, 0.0014024744741618633, 0.00244514225050807, 0.0017486769938841462, 0.0018574848072603345, 0.002325895708054304, 0.0017648569773882627, 0.0020058685913681984, 0.001941308262757957, 0.0018749090377241373, 0.0023797533940523863, 0.0018764223204925656, 0.0018148364033550024, 0.0015358468517661095, 0.0014845207333564758, 0.0025310625787824392, 0.0021996921859681606, 0.00183179322630167, 0.0025857598520815372, 0.0021644725929945707, 0.0015618524048477411, 0.0016689441399648786, 0.002032040385529399, 0.001992176752537489, 0.0016410256503149867, 0.0021011470817029476, 0.0018611378036439419, 0.0019806420896202326, 0.001919315429404378, 0.0018942755414173007, 0.0014493780909106135, 0.0017581761348992586, 0.0016265347367152572, 0.0014837102498859167, 0.0021634416189044714, 0.001967955846339464, 0.0020422900561243296, 0.0016099570784717798, 0.0018796813674271107, 0.00220391433686018, 0.001995860133320093, 0.0028514652512967587, 0.0023962289560586214, 0.0017511280020698905, 0.0019804632756859064, 0.0021230578422546387, 0.001952311140485108, 0.001814729650504887, 0.0015874786768108606, 0.0018784870626404881, 0.002173812361434102, 0.0018200785852968693]\n",
      "  New scales: [0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.0009765625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.0009765625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125]\n",
      "  Zero points: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[Per-channel] hgates:\n",
      "  Old scales: [0.0029182026628404856, 0.0026314600836485624, 0.0020051435567438602, 0.0027530489023774862, 0.002125341212376952, 0.0025776936672627926, 0.002889254130423069, 0.00208160188049078, 0.0021727285347878933, 0.0019883441273123026, 0.002303617773577571, 0.0025396801065653563, 0.002338280901312828, 0.001920179114677012, 0.002579196821898222, 0.0021412507630884647, 0.002221577800810337, 0.0024897686671465635, 0.0022722601424902678, 0.0022451227996498346, 0.0028128682170063257, 0.003486876143142581, 0.002328578382730484, 0.0024308161810040474, 0.0026374494191259146, 0.0037553119473159313, 0.0030547294300049543, 0.003254285780712962, 0.002645888365805149, 0.0026906158309429884, 0.0026270493399351835, 0.0022242777049541473, 0.002123418264091015, 0.002640903228893876, 0.003157039638608694, 0.0027971069794148207, 0.0024310159496963024, 0.002559807151556015, 0.0022172704339027405, 0.002826440380886197, 0.0025458773598074913, 0.0028779078274965286, 0.0030556481797248125, 0.0029392011929303408, 0.0029683508910238743, 0.002712134039029479, 0.002776945708319545, 0.004136872943490744, 0.0018313095206394792, 0.002654304262250662, 0.002317504957318306, 0.002382425358518958, 0.002728112740442157, 0.002867303555831313, 0.002150699496269226, 0.0017978115938603878, 0.0023417440243065357, 0.0023034950718283653, 0.00237544858828187, 0.0022949266713112593, 0.0032815870363265276, 0.0022346987389028072, 0.002220944967120886, 0.002376577816903591, 0.002431246219202876, 0.0022114969324320555, 0.002300227526575327, 0.002811807906255126, 0.0017775725573301315, 0.002838007640093565, 0.0025782384909689426, 0.0020523900166153908, 0.0032681638840585947, 0.0031119701452553272, 0.0031417151913046837, 0.003134537721052766, 0.003261151257902384, 0.002513709245249629, 0.0032779714092612267, 0.0025512496940791607, 0.0031233078334480524, 0.003426396520808339, 0.002992285182699561, 0.002637996571138501, 0.0031011709943413734, 0.0025896024890244007, 0.0031213450711220503, 0.0028496060986071825, 0.0031931581906974316, 0.0025774806272238493, 0.0023981956765055656, 0.0036941005382686853, 0.0028599840588867664, 0.0030994052067399025, 0.003437604056671262, 0.002827514661476016]\n",
      "  New scales: [0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625]\n",
      "  Zero points: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[Per-channel] igates:\n",
      "  Old scales: [0.0021003223955631256, 0.0020789599511772394, 0.002670819405466318, 0.0018972918624058366, 0.0026637951377779245, 0.0027115263510495424, 0.0019669518806040287, 0.0023538500536233187, 0.0025483262725174427, 0.0025497835595160723, 0.0022379334550350904, 0.002190364757552743, 0.0027367710135877132, 0.0023798365145921707, 0.002284511923789978, 0.002663705497980118, 0.0018964683404192328, 0.002088497392833233, 0.0032843875233083963, 0.0025798575952649117, 0.0018963160691782832, 0.001931993756443262, 0.002112651476636529, 0.0031190088484436274, 0.0030046754982322454, 0.002648392226547003, 0.002611727686598897, 0.0027598824817687273, 0.003145662834867835, 0.003429828677326441, 0.003254059934988618, 0.0028424314223229885, 0.002731774002313614, 0.00248129665851593, 0.0029748419765383005, 0.002478065900504589, 0.0033498143311589956, 0.002801615511998534, 0.0034581960644572973, 0.002867181785404682, 0.002862835768610239, 0.0028453331906348467, 0.002064660657197237, 0.00361794070340693, 0.002732187742367387, 0.0024802277330309153, 0.0025999858044087887, 0.0027145964559167624, 0.0022281226702034473, 0.0025201640091836452, 0.0024518354330211878, 0.002754160203039646, 0.002622591331601143, 0.002025453606620431, 0.003215109696611762, 0.002171789761632681, 0.002010342199355364, 0.0020738006569445133, 0.0021514699328690767, 0.00232705008238554, 0.001989580923691392, 0.002445714781060815, 0.0025369988288730383, 0.0019907914102077484, 0.0021533395629376173, 0.0023979463148862123, 0.0037306533195078373, 0.0019557143095880747, 0.0016498974291607738, 0.0027472893707454205, 0.002524743555113673, 0.0024401755072176456, 0.003068233374506235, 0.0033272698055952787, 0.003490361152216792, 0.0032223446760326624, 0.0033403837587684393, 0.003433337900787592, 0.003401630325242877, 0.0030501249711960554, 0.0023490225430577993, 0.002576409140601754, 0.0031960883643478155, 0.0025954965967684984, 0.0030557471327483654, 0.0035012203734368086, 0.0035990364849567413, 0.0034797238186001778, 0.0032465073745697737, 0.0037619867362082005, 0.0034169149585068226, 0.0026995912194252014, 0.003111660247668624, 0.002454870380461216, 0.004070772789418697, 0.003258827608078718]\n",
      "  New scales: [0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.00390625]\n",
      "  Zero points: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[Per-channel] hgates:\n",
      "  Old scales: [0.0024179548490792513, 0.002377450466156006, 0.002454059664160013, 0.0024607814848423004, 0.0026171437930315733, 0.0023925926070660353, 0.002117685740813613, 0.0026489237789064646, 0.0019358572317287326, 0.002044501481577754, 0.0020945488940924406, 0.002009929157793522, 0.0020832205191254616, 0.0026351092383265495, 0.002439711708575487, 0.0025280823465436697, 0.0025786003097891808, 0.0030089630745351315, 0.0021980605088174343, 0.001973826438188553, 0.0028266748413443565, 0.0024252908769994974, 0.0025985923130065203, 0.0025291077326983213, 0.0031065044458955526, 0.00340602220967412, 0.002721000462770462, 0.0026539466343820095, 0.002123091369867325, 0.0026166862808167934, 0.002620353829115629, 0.0027787049766629934, 0.0025954495649784803, 0.0023696166463196278, 0.003326965030282736, 0.002878746250644326, 0.001775300013832748, 0.002639900194481015, 0.0026627625338733196, 0.0032942735124379396, 0.002127282787114382, 0.002895834157243371, 0.0022502592764794827, 0.0030765754636377096, 0.0022687395103275776, 0.00256272847764194, 0.0034579832572489977, 0.0019421061733737588, 0.002716328715905547, 0.002576808212324977, 0.002718979259952903, 0.0021004064474254847, 0.002499754773452878, 0.0023382382933050394, 0.002399792894721031, 0.0022029015235602856, 0.002565147588029504, 0.002416440285742283, 0.003064279444515705, 0.002058799611404538, 0.0025969818234443665, 0.002511207014322281, 0.0020588242914527655, 0.001611777232028544, 0.0022322104778140783, 0.002375106792896986, 0.002283932641148567, 0.002570715267211199, 0.00233995309099555, 0.002310416428372264, 0.0020903898403048515, 0.002247918862849474, 0.002955968491733074, 0.003386484691873193, 0.0022702915593981743, 0.0039083342999219894, 0.003807392902672291, 0.00249014631845057, 0.0027097342535853386, 0.0033052037470042706, 0.00267629511654377, 0.0030077563133090734, 0.0032309857197105885, 0.002245411043986678, 0.003401888767257333, 0.0026527857407927513, 0.002820309018716216, 0.0027731475420296192, 0.002945743268355727, 0.0033892628271132708, 0.003029828891158104, 0.003485074732452631, 0.002698628231883049, 0.0025002388283610344, 0.00323354615829885, 0.0026006107218563557]\n",
      "  New scales: [0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.001953125, 0.00390625, 0.00390625, 0.001953125, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.00390625, 0.001953125, 0.00390625, 0.001953125, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.001953125]\n",
      "  Zero points: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[Per-channel] fc:\n",
      "  Old scales: [0.006518076173961163, 0.004170414060354233, 0.005606438498944044, 0.004578213673084974, 0.005293615628033876, 0.004408139269798994, 0.004680196288973093, 0.0044132075272500515, 0.005934687796980143, 0.005583066493272781]\n",
      "  New scales: [0.0078125, 0.00390625, 0.0078125, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.0078125, 0.0078125]\n",
      "  Zero points: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "update_quantized_weights_and_show_scales(po2_quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b6750bf-44a9-4e6f-889b-f8cb15814dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate import ModelEvaluator\n",
    "quant_test_instance_2 = ModelEvaluator(\n",
    "    po2_quantized_model, \n",
    "    test_loader,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce129e4d-02c2-4e63-b6d8-228e603a7d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavan/Music/spectrum/spectgramer/lib/python3.10/site-packages/torch/ao/nn/quantizable/modules/rnn.py:543: UserWarning: All inputs of this cat operator must share the same quantization parameters. Otherwise large numerical inaccuracies may occur. (Triggered internally at /pytorch/aten/src/ATen/native/quantized/cpu/TensorShape.cpp:167.)\n",
      "  cx_tensor = torch.stack(cx_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy on test data: 83.17%\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8072    0.9306    0.8645        72\n",
      "           1     0.8776    0.6232    0.7288        69\n",
      "           2     0.9231    0.6316    0.7500        57\n",
      "           3     0.7397    0.9643    0.8372        56\n",
      "           4     0.9016    0.9322    0.9167        59\n",
      "           5     0.9492    0.8889    0.9180        63\n",
      "           6     0.8571    0.7500    0.8000        56\n",
      "           7     0.7059    0.8727    0.7805        55\n",
      "           8     0.8571    0.8421    0.8496        57\n",
      "           9     0.7937    0.8929    0.8403        56\n",
      "\n",
      "    accuracy                         0.8317       600\n",
      "   macro avg     0.8412    0.8328    0.8286       600\n",
      "weighted avg     0.8430    0.8317    0.8288       600\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[67  0  3  1  0  0  0  1  0  0]\n",
      " [ 7 43  0  0  5  0  1 13  0  0]\n",
      " [ 8  1 36  4  0  0  0  1  0  7]\n",
      " [ 0  0  0 54  0  0  0  0  1  1]\n",
      " [ 1  2  0  0 55  0  0  1  0  0]\n",
      " [ 0  0  0  0  1 56  0  3  0  3]\n",
      " [ 0  0  0  7  0  0 42  0  7  0]\n",
      " [ 0  3  0  0  0  1  1 48  0  2]\n",
      " [ 0  0  0  4  0  0  5  0 48  0]\n",
      " [ 0  0  0  3  0  2  0  1  0 50]]\n"
     ]
    }
   ],
   "source": [
    "quant_test_instance_2.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85908e37-fd44-4d6d-bb55-c838081b6e6d",
   "metadata": {},
   "source": [
    "### Compute Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b5e572b-f3e9-413b-bb27-903d4bd15785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median inference time: 20.1323 ms\n"
     ]
    }
   ],
   "source": [
    "utils.compute_inference_time(po2_quantized_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6f22f-aa8e-47bf-9d28-715b97642061",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caeca747-03e1-4ef6-a5f2-ccf9deb44961",
   "metadata": {},
   "outputs": [],
   "source": [
    "po2_quantized_model.eval()\n",
    "\n",
    "po2_quantized_model_save_path = os.path.join(project_root_dir, 'outputs', 'models', 'task-b-part-2_weights_jit.pth')\n",
    "script_model = torch.jit.script(po2_quantized_model)\n",
    "torch.jit.save(script_model, po2_quantized_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a2ac2-1cc6-4fca-b780-b4462f92df9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed11efa0-b929-409d-aa86-c40528c3b9cc",
   "metadata": {},
   "source": [
    "## Does the Model Layer Parameters meet 36 KB Memory Constraint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71e57e19-1515-49d5-8ad3-15d0e45c1fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model - Layer Analysis\n",
      "Layer Name                               | Num Parameters | Size (INT8) | Fits in 36KB?\n",
      "---------------------------------------------------------------------------\n",
      "model.lstm.layers.0.layer_fw.cell.igates |          1248 | 1.219 KB     | âœ…\n",
      "model.lstm.layers.0.layer_fw.cell.hgates |          2304 | 2.250 KB     | âœ…\n",
      "model.lstm.layers.1.layer_fw.cell.igates |          2304 | 2.250 KB     | âœ…\n",
      "model.lstm.layers.1.layer_fw.cell.hgates |          2304 | 2.250 KB     | âœ…\n",
      "model.fc                                 |           240 | 0.234 KB     | âœ…\n",
      "\n",
      "ðŸ“¦ Total Estimated Memory Usage\n",
      "Total number of parameters:      8400\n",
      "Estimated total size (INT8):     8.203 KB\n",
      "Memory per parameter (INT8):     1 byte\n",
      "Meets 36KB per-layer limit?      âœ… Yes\n"
     ]
    }
   ],
   "source": [
    "utils.print_quantized_layer_analysis(po2_quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3d12f-6e8a-43a9-92f2-86ad86180051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3afa9a88-2252-4cbe-9377-010925a912c4",
   "metadata": {},
   "source": [
    "## Does the Model use Power-of-Two Scale factors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40b416c3-8cd0-4b15-ae5c-baa4f47e88cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name                          | Scale Value     | Is Power of Two?\n",
      "----------------------------------------------------------------------\n",
      "model.lstm.layers.0.layer_fw.cell.igates | [0.001953125, 0.001953125, 0.001953125, ... | âœ…\n",
      "model.lstm.layers.0.layer_fw.cell.hgates | [0.00390625, 0.001953125, 0.001953125, 0... | âœ…\n",
      "model.lstm.layers.1.layer_fw.cell.igates | [0.001953125, 0.001953125, 0.001953125, ... | âœ…\n",
      "model.lstm.layers.1.layer_fw.cell.hgates | [0.001953125, 0.001953125, 0.001953125, ... | âœ…\n",
      "model.fc                            | [0.0078125, 0.00390625, 0.0078125, 0.003... | âœ…\n",
      "\n",
      " Final Result\n",
      "âœ… All layers use power-of-two scale values.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.verify_power_of_two_scales(po2_quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc090e53-f9f8-49fd-81ac-7936d481e5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spectgramer)",
   "language": "python",
   "name": "innatera-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
