{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ac121864-dea8-4206-b0d1-1acbdc0002dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root (parent of current folder) to Python path\n",
    "project_root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fc007882-2f6c-4e2e-9a19-18eb3a3dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907bf1a-f498-4c4b-941a-1ec9859a6dbc",
   "metadata": {},
   "source": [
    "## Read Yaml File for Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "51de20a8-e68c-40e3-b17b-f2cc330329ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": {\n",
      "    \"name\": \"lstm_audio_classifier\",\n",
      "    \"type\": \"LSTM\",\n",
      "    \"input_dim\": 13,\n",
      "    \"hidden_dim\": 128,\n",
      "    \"num_layers\": 2,\n",
      "    \"output_dim\": 10,\n",
      "    \"bidirectional\": false,\n",
      "    \"dropout_rate\": 0.3\n",
      "  },\n",
      "  \"training\": {\n",
      "    \"batch_size\": 32,\n",
      "    \"epochs\": 20,\n",
      "    \"learning_rate\": 0.001,\n",
      "    \"optimizer\": \"adam\",\n",
      "    \"loss_function\": \"cross_entropy\",\n",
      "    \"early_stopping\": true,\n",
      "    \"patience\": 5\n",
      "  },\n",
      "  \"data_splitting\": {\n",
      "    \"test_size\": 0.2,\n",
      "    \"random_state\": 42\n",
      "  },\n",
      "  \"dataset\": {\n",
      "    \"name\": \"Free Spoken Digits Dataset\",\n",
      "    \"path\": \"/home/pavan/Music/spectrum/free-spoken-digit-dataset/recordings\",\n",
      "    \"preprocessing\": {\n",
      "      \"denoise\": false\n",
      "    }\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"save_dir\": \"outputs/models/\",\n",
      "    \"log_dir\": \"outputs/logs/\",\n",
      "    \"save_best_model\": true,\n",
      "    \"model_filename\": \"lstm_audio_classifier.pt\"\n",
      "  },\n",
      "  \"hardware\": {\n",
      "    \"device\": \"cuda\"\n",
      "  },\n",
      "  \"hardware_constraints\": {\n",
      "    \"memory_size_limit\": 36\n",
      "  },\n",
      "  \"experiment\": {\n",
      "    \"seed\": 42\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "model_config_path = os.path.join(project_root_dir, 'config', 'model_config.yaml')\n",
    "with open(model_config_path, \"r\") as f:\n",
    "    model_config = yaml.safe_load(f)\n",
    "\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db000b-c161-4faf-b555-80a64696bed4",
   "metadata": {},
   "source": [
    "## Fetch Data Lable Pairs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd4c30c2-fdc9-4d1f-8491-8948e8a844c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = model_config['dataset']['path']\n",
    "test_data_size = model_config['data_splitting']['test_size']\n",
    "seed = model_config['experiment']['seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3f2e678e-b078-4b6d-8788-4807fc2912a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_pairs = utils.prepare_data_label_pairs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d5b6e981-6360-4c48-bf87-4d722523a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data_label_pairs, test_size=test_data_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d7a181bb-fce0-4dc5-aba6-b0cc522854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import SpokenDigitDataset\n",
    "\n",
    "train_dataset = SpokenDigitDataset(train_data)\n",
    "test_dataset = SpokenDigitDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0058f265-eea9-40db-8cfa-ab023f5feaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset.__getitem__(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4121f284-fd0e-49aa-a47b-ebfde0f1e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2400\n",
      "Test size: 600\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a2957cdf-bee7-4877-87c8-c4eeb186b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a30ecd48-25db-4e42-92e7-173fd8894e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = model_config['model']['input_dim']\n",
    "hidden_dim = model_config['model']['hidden_dim']\n",
    "num_layers = model_config['model']['num_layers']\n",
    "output_dim = model_config['model']['output_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b6a3b93e-82ab-4347-99ef-5be89844a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "acc6726e-a78c-4846-900e-d1f38377c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model as model\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = model.LSTMClassifier(input_dim=input_dim,\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       num_layers=num_layers,\n",
    "                       output_dim=output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b4bcea8-c7ff-46d4-b391-78c08e05adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = model_config['training']['learning_rate']\n",
    "epochs = model_config['training']['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "59d97af0-0fa0-44c6-a66e-68805db8fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import ModelTrainer\n",
    "trainer_instance = ModelTrainer(\n",
    "    model, \n",
    "    epochs,\n",
    "    train_loader,\n",
    "    device,\n",
    "    learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b93e3b2c-3a36-4320-99a8-4ec297bd853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 133.6825, Accuracy: 69.04%\n",
      "Epoch [2/5], Loss: 47.6737, Accuracy: 92.12%\n",
      "Epoch [3/5], Loss: 17.8605, Accuracy: 96.58%\n",
      "Epoch [4/5], Loss: 14.0454, Accuracy: 95.42%\n",
      "Epoch [5/5], Loss: 6.7255, Accuracy: 98.96%\n"
     ]
    }
   ],
   "source": [
    "trainer_instance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dbd17cd3-e337-43b2-b8fd-08297ef05941",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_model_params_size' from 'src.utils' (/home/pavan/Music/spectrum/fsdd-speech-recognition/src/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_model_params_size\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_model_params_size' from 'src.utils' (/home/pavan/Music/spectrum/fsdd-speech-recognition/src/utils.py)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f947da-ba60-44fc-9d7d-1554804a6f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef20b9c-08b9-42c9-ae8b-93b7e7c4f295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e00d21-ba5c-4cdb-986a-978ccc3d0d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spectgramer)",
   "language": "python",
   "name": "innatera-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
