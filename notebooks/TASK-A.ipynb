{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074e24f9-a286-43cd-965b-1c41044ee99b",
   "metadata": {},
   "source": [
    "## LSTM for Spoken Digit Classification: Train without constraints\n",
    "\n",
    "This notebook builds and trains a recurrent neural network (LSTM) to classify spoken digits (0–9) from audio recordings.\n",
    "\n",
    "- Dataset: [Free Spoken Digit Dataset (FSDD)](https://github.com/Jakobovski/free-spoken-digit-dataset)\n",
    "- Framework: PyTorch\n",
    "- Architecture: RNN with LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac121864-dea8-4206-b0d1-1acbdc0002dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root (parent of current folder) to Python path\n",
    "project_root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907bf1a-f498-4c4b-941a-1ec9859a6dbc",
   "metadata": {},
   "source": [
    "## Load Model Configuration from YAML\n",
    "\n",
    "To make the training pipeline configurable and modular, we store model parameters like number of LSTM layers, hidden size, and learning rate etc in a YAML file. This structure enables quick adaptation to related tasks B, and C.\n",
    "\n",
    "This section loads the model configuration using a custom utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc007882-2f6c-4e2e-9a19-18eb3a3dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5efd2eb-0415-43c9-ba38-492a135899d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "utils.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51de20a8-e68c-40e3-b17b-f2cc330329ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "\n",
    "model_config_path = os.path.join(project_root_dir, 'config', 'model_config.yaml')\n",
    "model_config = utils.read_yaml_file(model_config_path)\n",
    "# print(json.dumps(model_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db000b-c161-4faf-b555-80a64696bed4",
   "metadata": {},
   "source": [
    "## Load and Split Dataset for Training and Evaluation\n",
    "\n",
    "In this section, we load the recordings data from disk, generate data-label pairs, and split them into training and test sets according to the `test_size` defined in the YAML file.\n",
    "\n",
    "Using `test_size` and `seed` from the YAML config ensures that experiments are reproducible and easily tunable for other tasks by simply updating the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4c30c2-fdc9-4d1f-8491-8948e8a844c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = model_config['dataset']['path']\n",
    "test_data_size = model_config['data_splitting']['test_size']\n",
    "seed = model_config['experiment']['seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2e678e-b078-4b6d-8788-4807fc2912a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_pairs, _ = utils.prepare_data_label_pairs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b6e981-6360-4c48-bf87-4d722523a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data_label_pairs, test_size=test_data_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8a06f-d118-462d-987e-c5ee7363933c",
   "metadata": {},
   "source": [
    "## Transform Raw Data into PyTorch Dataset Objects\n",
    "\n",
    "The `AudioFeaturesDataset` class converts raw data-label pairs into PyTorch-compatible datasets that provide easy access to samples and labels.\n",
    "\n",
    "AudioFeaturesDataset is a custom dataset class that:\n",
    "\n",
    "- Loads audio recordings of spoken digits along with their labels.\n",
    "- Optionally cleans the audio by filtering out noise.\n",
    "- Extracts MFCC features (a common speech feature).\n",
    "- Pads or trims these features to a fixed length so all inputs have the same shape.\n",
    "- Works with PyTorch to provide samples one-by-one when training or testing a model.\n",
    "- It helps prepare your audio data in the right format for training neural networks efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7a181bb-fce0-4dc5-aba6-b0cc522854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessor import AudioFeaturesDataset\n",
    "\n",
    "train_dataset = AudioFeaturesDataset(train_data)\n",
    "test_dataset = AudioFeaturesDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4121f284-fd0e-49aa-a47b-ebfde0f1e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2400\n",
      "Test size: 600\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682500e-8660-481b-a3a8-823d4e824486",
   "metadata": {},
   "source": [
    "## Create DataLoaders for Batch Processing\n",
    "\n",
    "Using PyTorch DataLoaders, we enable efficient loading, batching, and shuffling of data during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2957cdf-bee7-4877-87c8-c4eeb186b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f7c9b-69cc-4239-837f-c1c82e9f3695",
   "metadata": {},
   "source": [
    "## LSTM Model Definition\n",
    "\n",
    "A simple `n`-layer LSTM followed by a fully connected output layer. Variable `n` is defined in the configuration YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a30ecd48-25db-4e42-92e7-173fd8894e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = model_config['model']['input_dim']\n",
    "hidden_dim = model_config['model']['hidden_dim']\n",
    "num_layers = model_config['model']['num_layers']\n",
    "output_dim = model_config['model']['output_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6a3b93e-82ab-4347-99ef-5be89844a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc6726e-a78c-4846-900e-d1f38377c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model as model\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "float_model = model.LSTMClassifier(input_dim=input_dim,\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       num_layers=num_layers,\n",
    "                       output_dim=output_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b334d1-1991-454e-9b55-4621c7c63362",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b4bcea8-c7ff-46d4-b391-78c08e05adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = model_config['training']['learning_rate']\n",
    "epochs = model_config['training']['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59d97af0-0fa0-44c6-a66e-68805db8fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import ModelTrainer\n",
    "trainer_instance = ModelTrainer(\n",
    "    float_model, \n",
    "    epochs,\n",
    "    train_loader,\n",
    "    device,\n",
    "    learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93e3b2c-3a36-4320-99a8-4ec297bd853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 135.5336, Accuracy: 57.92%\n",
      "Epoch [2/20], Loss: 60.2363, Accuracy: 87.79%\n",
      "Epoch [3/20], Loss: 25.2365, Accuracy: 95.75%\n",
      "Epoch [4/20], Loss: 15.5873, Accuracy: 96.46%\n",
      "Epoch [5/20], Loss: 12.0516, Accuracy: 97.29%\n",
      "Epoch [6/20], Loss: 6.3865, Accuracy: 99.08%\n",
      "Epoch [7/20], Loss: 5.4559, Accuracy: 96.46%\n",
      "Epoch [8/20], Loss: 7.2806, Accuracy: 97.54%\n",
      "Epoch [9/20], Loss: 5.7572, Accuracy: 98.75%\n",
      "Epoch [10/20], Loss: 7.9146, Accuracy: 98.42%\n",
      "Epoch [11/20], Loss: 3.3656, Accuracy: 99.62%\n",
      "Epoch [12/20], Loss: 1.4955, Accuracy: 99.83%\n",
      "Epoch [13/20], Loss: 0.9625, Accuracy: 99.88%\n",
      "Epoch [14/20], Loss: 0.5560, Accuracy: 99.96%\n",
      "Epoch [15/20], Loss: 0.3895, Accuracy: 99.96%\n",
      "Epoch [16/20], Loss: 0.3192, Accuracy: 99.96%\n",
      "Epoch [17/20], Loss: 0.1587, Accuracy: 99.96%\n",
      "Epoch [18/20], Loss: 0.3076, Accuracy: 99.92%\n",
      "Epoch [19/20], Loss: 0.2430, Accuracy: 99.96%\n",
      "Epoch [20/20], Loss: 0.1775, Accuracy: 99.96%\n"
     ]
    }
   ],
   "source": [
    "trainer_instance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd17cd3-e337-43b2-b8fd-08297ef05941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer-wise parameter counts:\n",
      "lstm.weight_ih_l0              -> 6,656 params\n",
      "lstm.weight_hh_l0              -> 65,536 params\n",
      "lstm.bias_ih_l0                -> 512 params\n",
      "lstm.bias_hh_l0                -> 512 params\n",
      "lstm.weight_ih_l1              -> 65,536 params\n",
      "lstm.weight_hh_l1              -> 65,536 params\n",
      "lstm.bias_ih_l1                -> 512 params\n",
      "lstm.bias_hh_l1                -> 512 params\n",
      "fc.weight                      -> 1,280 params\n",
      "fc.bias                        -> 10 params\n",
      "\n",
      "\n",
      " Total Parameters: 206,602\n",
      "Estimated Memory: 807.04 KB (0.79 MB)\n"
     ]
    }
   ],
   "source": [
    "_, _ = utils.get_model_params_size(float_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e192852-2d93-484f-b4f1-69f4689d730f",
   "metadata": {},
   "source": [
    "## Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85f947da-ba60-44fc-9d7d-1554804a6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate import ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef20b9c-08b9-42c9-ae8b-93b7e7c4f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instance = ModelEvaluator(\n",
    "    float_model, \n",
    "    test_loader,\n",
    "    device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52e00d21-ba5c-4cdb-986a-978ccc3d0d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy on test data: 99.00%\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9861    0.9861    0.9861        72\n",
      "           1     0.9855    0.9855    0.9855        69\n",
      "           2     0.9825    0.9825    0.9825        57\n",
      "           3     1.0000    1.0000    1.0000        56\n",
      "           4     1.0000    1.0000    1.0000        59\n",
      "           5     1.0000    0.9841    0.9920        63\n",
      "           6     0.9825    1.0000    0.9912        56\n",
      "           7     0.9821    1.0000    0.9910        55\n",
      "           8     1.0000    1.0000    1.0000        57\n",
      "           9     0.9818    0.9643    0.9730        56\n",
      "\n",
      "    accuracy                         0.9900       600\n",
      "   macro avg     0.9900    0.9902    0.9901       600\n",
      "weighted avg     0.9900    0.9900    0.9900       600\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[71  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 68  1  0  0  0  0  0  0  0]\n",
      " [ 1  0 56  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 56  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 59  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 62  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 56  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 55  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 57  0]\n",
      " [ 0  1  0  0  0  0  0  1  0 54]]\n"
     ]
    }
   ],
   "source": [
    "test_instance.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c20543-b2b0-4177-850c-a4f3986f784e",
   "metadata": {},
   "source": [
    "### Compute Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a12eaeb-9042-4a15-af4c-5834ad19b9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median inference time: 0.9460 ms\n"
     ]
    }
   ],
   "source": [
    "utils.compute_inference_time(float_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3590201-9194-4026-ba1e-bab41f554242",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7233c710-d50f-481e-a346-72a8eb705976",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_model_save_path = os.path.join(project_root_dir, 'outputs', 'models', 'float_model_weights.pth')\n",
    "torch.save(float_model.state_dict(), float_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd973c84-9999-40d6-9168-1b34f1fcc4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddcad9c6-0dfe-4158-9e2a-a09f7f9ec344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name                | Num Parameters | Size (Memory)\n",
      "----------------------------------------------------------------------\n",
      "lstm.weight_ih_l0         |          6656 | 26.000 KB \n",
      "lstm.weight_hh_l0         |         65536 | 256.000 KB \n",
      "lstm.bias_ih_l0           |           512 | 2.000 KB \n",
      "lstm.bias_hh_l0           |           512 | 2.000 KB \n",
      "lstm.weight_ih_l1         |         65536 | 256.000 KB \n",
      "lstm.weight_hh_l1         |         65536 | 256.000 KB \n",
      "lstm.bias_ih_l1           |           512 | 2.000 KB \n",
      "lstm.bias_hh_l1           |           512 | 2.000 KB \n",
      "fc.weight                 |          1280 | 5.000 KB \n",
      "fc.bias                   |            10 | 0.039 KB \n",
      "\n",
      "📊 Total Model Summary\n",
      "Total number of parameters:      206602\n",
      "Estimated total size (FP32):    807.04 KB (0.79 MB)\n",
      "Memory per parameter (FP32):    4 bytes\n",
      "Meets 36KB per-layer limit?     ❌ No\n"
     ]
    }
   ],
   "source": [
    "utils.print_float_model_analysis(float_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cee7da-3040-4715-8b30-966a2f600eaa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8e493-4e1f-4804-8ad5-ff26fa86a8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spectgramer)",
   "language": "python",
   "name": "innatera-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
